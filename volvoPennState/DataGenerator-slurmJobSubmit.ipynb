{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167a9ca2-b7be-442b-b3e6-c160215bdc9c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install SQLAlchemy\n",
    "# !pip install pyspark\n",
    "# !pip install jupysql duckdb duckdb-engine\n",
    "# !pip install delta-spark\n",
    "# !pip install py4j\n",
    "# !pip install -q findspark\n",
    "# conda install -c conda-forge submitit \n",
    "# conda install corn, nbconvert\n",
    "# !pip install graphviz\n",
    "# !pip install hydra-core\n",
    "# !pip install hydra-submitit-launcher\n",
    "# !pip install submitit\n",
    "# !pip install covalent-slurm-plugin\n",
    "# !pip install ipynb-py-convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368574ca-80d4-413c-804b-a86c05c1339f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVA_HOME=/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64\n",
      "env: PATH=/storage/home/yqf5148/work/anaconda3/envs/volvopennstate-env/bin:storage/icds/swst/deployed/production/20220813/apps/anaconda3/2021.05_gcc-8.5.0/bin:/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin\n"
     ]
    }
   ],
   "source": [
    "%env JAVA_HOME=/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64\n",
    "%env PATH=/storage/home/yqf5148/work/anaconda3/envs/volvopennstate-env/bin:storage/icds/swst/deployed/production/20220813/apps/anaconda3/2021.05_gcc-8.5.0/bin:/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "302060b9-b23b-4dab-8fe9-4d92a71d0ecb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ps: /storage/icds/RISE/sw8/anaconda/anaconda3/envs/tensorflow/lib/libuuid.so.1: no version information available (required by /usr/lib64/libblkid.so.1)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/01 01:35:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/01 01:35:10 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark as psk\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# import submitit\n",
    "\n",
    "import time as t \n",
    "from datetime import date, datetime, timedelta\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from functools import reduce  \n",
    "from math import modf\n",
    "import sqlite3\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from delta import * \n",
    "from delta.tables import *\n",
    "from delta import configure_spark_with_delta_pip\n",
    "# import covalent as ct\n",
    "\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# os.environ['PYDEVD_DISABLE_FILE_VALIDATION']=1\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "       .master(\"local[2]\") \\\n",
    "       .appName(\"MyApp\") \\\n",
    "       .config(\"spark.driver.maxResultSize\", \"20g\")\\\n",
    "       .config(\"spark.driver.memory\", \"100g\")\\\n",
    "       .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# sqlContext = SQLContext(sc)\n",
    "\n",
    "\n",
    "#both works\n",
    "# 1: \n",
    "# spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")    #To resolve the error for p1075_38 to_timestamp formating: You may get a different result due to the upgrading to Spark >= 3.0: Fail to parse '1/2/2019 20:40:00' in the new parser. You can set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0, or set to CORRECTED and treat it as an invalid datetime string.\n",
    "# Set Spark SQL legacy time parser policy to LEGACY to handle older date formats\n",
    "# 2:\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "# Increase the max fields in the string representation of a plan\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 1000)  # Increase to 1000 or more as needed\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"false\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d57ba81-4151-4ad1-8951-9bbfe610f092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"/storage/home/yqf5148/work/volvoPennState/data/dataset/VINs_data.csv\") \\\n",
    "          .createOrReplaceTempView(\"VINs_data\")\n",
    "\n",
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"/storage/home/yqf5148/work/volvoPennState/PopulationWithChassisId.csv\") \\\n",
    "          .createOrReplaceTempView(\"population\")\n",
    "df_population = spark.sql(\"SELECT * FROM population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b48cf55-1f5a-4eb2-9e66-620bf82d6a86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headerList = [    \n",
    "          \"calendar_day\", \n",
    "          \"f_1_dtc38_1th_15d\", \n",
    "          \"f_1_dtc38_2nd_15d\", \n",
    "          \"f_2_dtc38_1th_15d\", \n",
    "          \"f_2_dtc38_2nd_15d\", \n",
    "          \"f_3_dtc38_1th_15d\", \n",
    "          \"f_3_dtc38_2nd_15d\", \n",
    "          \"f_4_dtc38_1th_15d\", \n",
    "          \"f_4_dtc38_2nd_15d\", \n",
    "          \"f_5_dtc38_1th_15d\", \n",
    "          \"f_5_dtc38_2nd_15d\", \n",
    "          \"f_6_dtc38_1th_15d\", \n",
    "          \"f_6_dtc38_2nd_15d\", \n",
    "          \"f_7_dtc38_1th_15d\", \n",
    "          \"f_7_dtc38_2nd_15d\", \n",
    "          \"f_8_dtc38_1th_15d\", \n",
    "          \"f_8_dtc38_2nd_15d\", \n",
    "\n",
    "          \"f_1_dtc75_1th_15d\", \n",
    "          \"f_1_dtc75_2nd_15d\", \n",
    "          \"f_2_dtc75_1th_15d\", \n",
    "          \"f_2_dtc75_2nd_15d\", \n",
    "          \"f_3_dtc75_1th_15d\", \n",
    "          \"f_3_dtc75_2nd_15d\", \n",
    "          \"f_4_dtc75_1th_15d\", \n",
    "          \"f_4_dtc75_2nd_15d\", \n",
    "          \"f_5_dtc75_1th_15d\", \n",
    "          \"f_5_dtc75_2nd_15d\", \n",
    "          \"f_6_dtc75_1th_15d\", \n",
    "          \"f_6_dtc75_2nd_15d\", \n",
    "          \"f_7_dtc75_1th_15d\", \n",
    "          \"f_7_dtc75_2nd_15d\", \n",
    "          \"f_8_dtc75_1th_15d\", \n",
    "          \"f_8_dtc75_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc77_1th_15d\", \n",
    "          \"f_1_dtc77_2nd_15d\", \n",
    "          \"f_2_dtc77_1th_15d\", \n",
    "          \"f_2_dtc77_2nd_15d\", \n",
    "          \"f_3_dtc77_1th_15d\", \n",
    "          \"f_3_dtc77_2nd_15d\", \n",
    "          \"f_4_dtc77_1th_15d\", \n",
    "          \"f_4_dtc77_2nd_15d\", \n",
    "          \"f_5_dtc77_1th_15d\", \n",
    "          \"f_5_dtc77_2nd_15d\", \n",
    "          \"f_6_dtc77_1th_15d\", \n",
    "          \"f_6_dtc77_2nd_15d\", \n",
    "          \"f_7_dtc77_1th_15d\", \n",
    "          \"f_7_dtc77_2nd_15d\", \n",
    "          \"f_8_dtc77_1th_15d\", \n",
    "          \"f_8_dtc77_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc86_1th_15d\", \n",
    "          \"f_1_dtc86_2nd_15d\", \n",
    "          \"f_2_dtc86_1th_15d\", \n",
    "          \"f_2_dtc86_2nd_15d\", \n",
    "          \"f_3_dtc86_1th_15d\", \n",
    "          \"f_3_dtc86_2nd_15d\", \n",
    "          \"f_4_dtc86_1th_15d\", \n",
    "          \"f_4_dtc86_2nd_15d\", \n",
    "          \"f_5_dtc86_1th_15d\", \n",
    "          \"f_5_dtc86_2nd_15d\", \n",
    "          \"f_6_dtc86_1th_15d\", \n",
    "          \"f_6_dtc86_2nd_15d\", \n",
    "          \"f_7_dtc86_1th_15d\", \n",
    "          \"f_7_dtc86_2nd_15d\", \n",
    "          \"f_8_dtc86_1th_15d\", \n",
    "          \"f_8_dtc86_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc92_1th_15d\", \n",
    "          \"f_1_dtc92_2nd_15d\", \n",
    "          \"f_2_dtc92_1th_15d\", \n",
    "          \"f_2_dtc92_2nd_15d\", \n",
    "          \"f_3_dtc92_1th_15d\", \n",
    "          \"f_3_dtc92_2nd_15d\", \n",
    "          \"f_4_dtc92_1th_15d\", \n",
    "          \"f_4_dtc92_2nd_15d\", \n",
    "          \"f_5_dtc92_1th_15d\", \n",
    "          \"f_5_dtc92_2nd_15d\", \n",
    "          \"f_6_dtc92_1th_15d\", \n",
    "          \"f_6_dtc92_2nd_15d\", \n",
    "          \"f_7_dtc92_1th_15d\", \n",
    "          \"f_7_dtc92_2nd_15d\", \n",
    "          \"f_8_dtc92_1th_15d\", \n",
    "          \"f_8_dtc92_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc94_1th_15d\", \n",
    "          \"f_1_dtc94_2nd_15d\", \n",
    "          \"f_2_dtc94_1th_15d\", \n",
    "          \"f_2_dtc94_2nd_15d\", \n",
    "          \"f_3_dtc94_1th_15d\", \n",
    "          \"f_3_dtc94_2nd_15d\", \n",
    "          \"f_4_dtc94_1th_15d\", \n",
    "          \"f_4_dtc94_2nd_15d\", \n",
    "          \"f_5_dtc94_1th_15d\", \n",
    "          \"f_5_dtc94_2nd_15d\", \n",
    "          \"f_6_dtc94_1th_15d\", \n",
    "          \"f_6_dtc94_2nd_15d\", \n",
    "          \"f_7_dtc94_1th_15d\", \n",
    "          \"f_7_dtc94_2nd_15d\", \n",
    "          \"f_8_dtc94_1th_15d\", \n",
    "          \"f_8_dtc94_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc0401_1th_15d\", \n",
    "          \"f_1_dtc0401_2nd_15d\", \n",
    "          \"f_2_dtc0401_1th_15d\", \n",
    "          \"f_2_dtc0401_2nd_15d\", \n",
    "          \"f_3_dtc0401_1th_15d\", \n",
    "          \"f_3_dtc0401_2nd_15d\", \n",
    "          \"f_4_dtc0401_1th_15d\", \n",
    "          \"f_4_dtc0401_2nd_15d\", \n",
    "          \"f_5_dtc0401_1th_15d\", \n",
    "          \"f_5_dtc0401_2nd_15d\", \n",
    "          \"f_6_dtc0401_1th_15d\", \n",
    "          \"f_6_dtc0401_2nd_15d\", \n",
    "          \"f_7_dtc0401_1th_15d\", \n",
    "          \"f_7_dtc0401_2nd_15d\", \n",
    "          \"f_8_dtc0401_1th_15d\", \n",
    "          \"f_8_dtc0401_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc2457_1th_15d\", \n",
    "          \"f_1_dtc2457_2nd_15d\", \n",
    "          \"f_2_dtc2457_1th_15d\", \n",
    "          \"f_2_dtc2457_2nd_15d\", \n",
    "          \"f_3_dtc2457_1th_15d\", \n",
    "          \"f_3_dtc2457_2nd_15d\", \n",
    "          \"f_4_dtc2457_1th_15d\", \n",
    "          \"f_4_dtc2457_2nd_15d\", \n",
    "          \"f_5_dtc2457_1th_15d\", \n",
    "          \"f_5_dtc2457_2nd_15d\", \n",
    "          \"f_6_dtc2457_1th_15d\", \n",
    "          \"f_6_dtc2457_2nd_15d\", \n",
    "          \"f_7_dtc2457_1th_15d\", \n",
    "          \"f_7_dtc2457_2nd_15d\", \n",
    "          \"f_8_dtc2457_1th_15d\", \n",
    "          \"f_8_dtc2457_2nd_15d\",\n",
    "\n",
    "          \"if_parts_replaced_in_1th_15d\", \n",
    "          \"if_parts_replaced_in_2nd_15d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75cf5e13-2336-48ce-ad2b-a04c0f987935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def whether_thisVIN_data_already_generated(thisVIN): \n",
    "    df_VINs_data = spark.sql(\"SELECT * FROM VINs_data\")\n",
    "    df_VINs_data = df_VINs_data.toDF(\"VIN\", \"TOTAL_ROWS\")\n",
    "    df_VINs_data_p = df_VINs_data.toPandas()\n",
    "    for index, row in df_VINs_data_p.iterrows():\n",
    "        if row['VIN'] == thisVIN:\n",
    "          return 1\n",
    "    return 0\n",
    "\n",
    "# Function to submit a SLURM job and return the job ID\n",
    "def submit_job1(script_path, thisVIN, account='vuh14_dibbs_sc', partition='sla-prio'):\n",
    "    submit_command = f\"sbatch --account={account} --partition={partition} {script_path} {thisVIN}\"\n",
    "    print(\"The submit command for the submitted job is: \")\n",
    "    print(submit_command)\n",
    "    result = subprocess.run(submit_command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        job_id = re.findall(r'\\d+', result.stdout)[0]\n",
    "        print(f\"Job {job_id} submitted successfully.\")\n",
    "        return job_id\n",
    "    else:\n",
    "        print(\"Job submission failed.\")\n",
    "        return None\n",
    "\n",
    "# Function to submit a SLURM job and return the job ID\n",
    "def submit_job2(script_path, thisVIN, calendar_day_from_where_it_left_off, account='vuh14_dibbs_sc', partition='sla-prio'):\n",
    "    submit_command = f\"sbatch --account={account} --partition={partition} {script_path} {thisVIN} {calendar_day_from_where_it_left_off}\"\n",
    "    print(\"The submit command for the submitted job is: \")\n",
    "    print(submit_command)\n",
    "    result = subprocess.run(submit_command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        job_id = re.findall(r'\\d+', result.stdout)[0]\n",
    "        print(f\"Job {job_id} submitted successfully.\")\n",
    "        return job_id\n",
    "    else:\n",
    "        print(\"Job submission failed.\")\n",
    "        return None\n",
    " \n",
    "# Function to check the status of multiple jobs\n",
    "def check_jobs_status(job_ids):\n",
    "    jobs_running = set(job_ids)\n",
    "    while jobs_running:\n",
    "        for job_id in list(jobs_running):\n",
    "            status_command = f\"squeue -j {job_id}\"\n",
    "            result = subprocess.run(status_command, shell=True, capture_output=True, text=True)\n",
    "            if not result.stdout:  # If the job is no longer in the queue\n",
    "                print(f\"Job {job_id} completed.\")\n",
    "                jobs_running.remove(job_id)\n",
    "        if jobs_running:\n",
    "            print(\"Some jobs are still running...\")\n",
    "            print(jobs_running)\n",
    "            t.sleep(1)  # Check every 5 seconds\n",
    "\n",
    "# Function to retrieve job outputs\n",
    "def get_jobs_output(output_files):\n",
    "    for output_file in output_files:\n",
    "        try:\n",
    "            with open(output_file, \"r\") as file:\n",
    "                output = file.read()\n",
    "            print(f\"Output from {output_file}:\")\n",
    "            print(output)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Output file {output_file} not found.\")\n",
    "            \n",
    "            \n",
    "def update_VINs_data_total_rows_from_resulted_data(vins_data_path, resulted_data_path, headerList):\n",
    "    import pandas as pd\n",
    "\n",
    "    # Step 1: Read VINs_data.csv\n",
    "    df_vins = pd.read_csv(vins_data_path, names=[\"VIN\", \"TOTAL_ROWS\"], dtype=str, header=None)\n",
    "\n",
    "    # Step 2: Read resultedData.csv with headerList, skipping bad lines\n",
    "    df_resulted = pd.read_csv(resulted_data_path, names=headerList, header=None, on_bad_lines='skip')\n",
    "\n",
    "    # Step 3: Ensure calendar_day is numeric\n",
    "    df_resulted[\"calendar_day\"] = pd.to_numeric(df_resulted[\"calendar_day\"], errors='coerce')\n",
    "\n",
    "    # Step 4: Filter and update VINs\n",
    "    updated_rows = []\n",
    "\n",
    "    for index, row in df_vins.iterrows():\n",
    "        vin = row['VIN']\n",
    "        matching_rows = df_resulted[df_resulted['VIN'] == vin]\n",
    "\n",
    "        if not matching_rows.empty:\n",
    "            max_day = matching_rows['calendar_day'].max()\n",
    "            print(f\" VIN: {vin} → Max calendar_day: {max_day}, Updating TOTAL_ROWS to: {int(max_day)}\")\n",
    "            updated_rows.append([vin, int(max_day)])\n",
    "        else:\n",
    "            print(f\" VIN: {vin} → No match in resultedData → Setting TOTAL_ROWS to 0\")\n",
    "            updated_rows.append([vin, 0])  # Mark for later removal\n",
    "\n",
    "    # Step 5: Create DataFrame and remove TOTAL_ROWS == 0\n",
    "    updated_df = pd.DataFrame(updated_rows, columns=[\"VIN\", \"TOTAL_ROWS\"])\n",
    "    updated_df = updated_df[updated_df[\"TOTAL_ROWS\"] != 0]\n",
    "\n",
    "    # Step 6: Overwrite VINs_data.csv\n",
    "    updated_df.to_csv(vins_data_path, index=False, header=False)\n",
    "\n",
    "    print(f\"\\n VINs_data.csv updated. Final row count (excluding TOTAL_ROWS=0): {len(updated_df)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "def is_valid_vin(vin: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns 1 if the VIN is valid, 0 if not.\n",
    "    A valid VIN is exactly 17 characters long and does not contain I, O, or Q.\n",
    "    \"\"\"\n",
    "    vin = vin.strip().upper()\n",
    "\n",
    "    # Rule 1: VIN must be exactly 17 characters\n",
    "    if len(vin) != 17:\n",
    "        return 0\n",
    "\n",
    "    # Rule 2: Must only contain A-H, J-N, P, R-Z, and 0-9 (excluding I, O, Q)\n",
    "    if not re.match(\"^[A-HJ-NPR-Z0-9]{17}$\", vin):\n",
    "        return 0\n",
    "\n",
    "    return 1  \n",
    "    \n",
    "    \n",
    "def update_VINs_data_from_resulted_data(vins_data_path, resulted_data_path, headerList):\n",
    "\n",
    "    # Columns: Keep selected + headers\n",
    "    selected_features_from_population = ['VIN', 'ENGINE_SIZE', 'ENGINE_HP', 'VEH_TYPE'] + [s for s in df_population.columns if 'KOLA' in s]\n",
    "    all_columns_names = selected_features_from_population + headerList\n",
    "\n",
    "    #  Step 1: Load VINs_data.csv\n",
    "    df_vins = pd.read_csv(VINs_data_file_path, names=[\"VIN\", \"TOTAL_ROWS\"], dtype={\"VIN\": str, \"TOTAL_ROWS\": int}, header=None)\n",
    "\n",
    "    #  Step 2: Load resultedData.csv (skip bad lines)\n",
    "    df_resulted = pd.read_csv(resulted_data_path, names=all_columns_names, header=None, on_bad_lines='skip')\n",
    "\n",
    "    #  Step 3: Convert calendar_day to numeric\n",
    "    df_resulted[\"calendar_day\"] = pd.to_numeric(df_resulted[\"calendar_day\"], errors='coerce')\n",
    "\n",
    "    #  Step 4: Group by VIN → max calendar_day\n",
    "    grouped = df_resulted.groupby(\"VIN\")[\"calendar_day\"].max().reset_index()\n",
    "    grouped.columns = [\"VIN\", \"MAX_CALENDAR_DAY\"]\n",
    "\n",
    "    #  Step 5: Build dictionary of existing VINs\n",
    "    vins_dict = dict(zip(df_vins[\"VIN\"], df_vins[\"TOTAL_ROWS\"]))\n",
    "\n",
    "    #  Step 6: Update or add VINs\n",
    "    updated_rows = []\n",
    "\n",
    "    for _, row in grouped.iterrows():\n",
    "        vin = row[\"VIN\"]\n",
    "        max_day_val = row[\"MAX_CALENDAR_DAY\"]\n",
    "\n",
    "        if(is_valid_vin(vin)==0):\n",
    "            print(f\" Skipping VIN: {vin} because it is invalid.\")\n",
    "            continue\n",
    "\n",
    "        if pd.isna(max_day_val):\n",
    "            print(f\" Skipping VIN: {vin} → MAX_CALENDAR_DAY is NaN\")\n",
    "            continue\n",
    "\n",
    "        max_day = int(max_day_val)\n",
    "\n",
    "        if vin in vins_dict:\n",
    "            print(f\" Updating VIN: {vin} → TOTAL_ROWS: {vins_dict[vin]} → {max_day}\")\n",
    "        else:\n",
    "            print(f\" Adding new VIN: {vin} → TOTAL_ROWS: {max_day}\")\n",
    "\n",
    "        updated_rows.append([vin, max_day])\n",
    "\n",
    "    #  Step 7: Add VINs from original not in grouped\n",
    "    existing_vins_set = set(grouped[\"VIN\"])\n",
    "    for vin, total_rows in vins_dict.items():\n",
    "        if vin not in existing_vins_set:\n",
    "            updated_rows.append([vin, total_rows])\n",
    "            print(f\" Keeping existing VIN: {vin} → TOTAL_ROWS: {total_rows}\")\n",
    "\n",
    "    #  Step 8: Save updated VINs\n",
    "    df_final = pd.DataFrame(updated_rows, columns=[\"VIN\", \"TOTAL_ROWS\"])\n",
    "    df_final.to_csv(VINs_data_file_path, index=False, header=False)\n",
    "\n",
    "    print(f\"\\n VINs_data.csv successfully updated. Total VINs: {len(df_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943cb4ff-422c-4413-9f5e-89384093f5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1065063/2802079158.py:131: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_resulted = pd.read_csv(resulted_data_path, names=all_columns_names, header=None, on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Skipping VIN: -AGS because it is invalid.\n",
      " Skipping VIN: -ST because it is invalid.\n",
      " Skipping VIN: .0 because it is invalid.\n",
      " Skipping VIN: 0 because it is invalid.\n",
      " Skipping VIN: 0.0 because it is invalid.\n",
      " Skipping VIN: 1 because it is invalid.\n",
      " Updating VIN: 1M1AN07Y3GM021042 → TOTAL_ROWS: 414 → 419\n",
      " Updating VIN: 1M1AN2AY5LM001812 → TOTAL_ROWS: 2084 → 2084\n",
      " Updating VIN: 1M1AN2GY3KM006268 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M1AN3GY4LM019358 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M1AN4GY0MM022958 → TOTAL_ROWS: 1914 → 1914\n",
      " Updating VIN: 1M1AN4GY0MM022961 → TOTAL_ROWS: 2339 → 2339\n",
      " Updating VIN: 1M1AN4GY7KM008343 → TOTAL_ROWS: 779 → 789\n",
      " Updating VIN: 1M1AN4GY8MM021279 → TOTAL_ROWS: 2199 → 2199\n",
      " Updating VIN: 1M1AN4GYXLM018348 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M1AW01Y2FM006911 → TOTAL_ROWS: 1433 → 1433\n",
      " Updating VIN: 1M1AW01Y5JM010413 → TOTAL_ROWS: 24 → 24\n",
      " Updating VIN: 1M1AW02Y1FM050302 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M1AW02Y7FM051728 → TOTAL_ROWS: 764 → 764\n",
      " Updating VIN: 1M1AW07Y4FM045037 → TOTAL_ROWS: 68 → 74\n",
      " Updating VIN: 1M2AU02C6GM010563 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M2AU04C5FM008959 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M2AV02C5JM018223 → TOTAL_ROWS: 2139 → 2139\n",
      " Updating VIN: 1M2AV02C6HM016569 → TOTAL_ROWS: 2244 → 2244\n",
      " Updating VIN: 1M2AX04C3GM030029 → TOTAL_ROWS: 743 → 749\n",
      " Updating VIN: 1M2AX04C7GM027070 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M2AX04C9HM034281 → TOTAL_ROWS: 1964 → 1964\n",
      " Updating VIN: 1M2AX07C0HM032978 → TOTAL_ROWS: 374 → 374\n",
      " Updating VIN: 1M2AX07C7FM024311 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M2AX13C1GM035012 → TOTAL_ROWS: 624 → 638\n",
      " Updating VIN: 1M2AX13C3HM037068 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M2AX13C4GM031245 → TOTAL_ROWS: 719 → 728\n",
      " Updating VIN: 1M2AX13C4JM040440 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M2AX13C9FM027402 → TOTAL_ROWS: 2108 → 2108\n",
      " Updating VIN: 1M2GR2GC1LM015017 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M2GR2GC2MM025105 → TOTAL_ROWS: 1979 → 1979\n",
      " Updating VIN: 1M2GR2GC6LM012730 → TOTAL_ROWS: 719 → 729\n",
      " Updating VIN: 1M2GR3GC2MM022467 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M2GR4GC0LM014601 → TOTAL_ROWS: 684 → 698\n",
      " Updating VIN: 1M2GR4GC0LM018549 → TOTAL_ROWS: 2198 → 2198\n",
      " Updating VIN: 1M2GR4GC8LM017763 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M2GR4GCXKM004284 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 1M2LR05C3HM001875 → TOTAL_ROWS: 788 → 794\n",
      " Updating VIN: 1M2TE2GC1LM003511 → TOTAL_ROWS: 2079 → 2079\n",
      " Skipping VIN: 2B because it is invalid.\n",
      " Skipping VIN: 3 because it is invalid.\n",
      " Updating VIN: 4V4M19EH8FN184640 → TOTAL_ROWS: 1479 → 1479\n",
      " Updating VIN: 4V4MC9EG6FN178787 → TOTAL_ROWS: 2054 → 2054\n",
      " Updating VIN: 4V4N19EH5LN221692 → TOTAL_ROWS: 794 → 803\n",
      " Updating VIN: 4V4N99EH3HN975934 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9DH1KN205824 → TOTAL_ROWS: 24 → 24\n",
      " Updating VIN: 4V4NC9EH0GN960694 → TOTAL_ROWS: 759 → 759\n",
      " Updating VIN: 4V4NC9EH0HN991459 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9EH0LN264590 → TOTAL_ROWS: 2138 → 2138\n",
      " Updating VIN: 4V4NC9EH1FN911535 → TOTAL_ROWS: 728 → 728\n",
      " Updating VIN: 4V4NC9EH1FN933289 → TOTAL_ROWS: 1013 → 1013\n",
      " Updating VIN: 4V4NC9EH1GN938316 → TOTAL_ROWS: 2168 → 2168\n",
      " Updating VIN: 4V4NC9EH1GN973065 → TOTAL_ROWS: 24 → 24\n",
      " Updating VIN: 4V4NC9EH2FN919420 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9EH2LN238489 → TOTAL_ROWS: 728 → 729\n",
      " Updating VIN: 4V4NC9EH2NN289266 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9EH4GN952713 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9EH4HN977144 → TOTAL_ROWS: 2124 → 2124\n",
      " Updating VIN: 4V4NC9EH4JN887837 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9EH4JN893072 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9EH4JN998906 → TOTAL_ROWS: 2124 → 2124\n",
      " Updating VIN: 4V4NC9EH5HN990971 → TOTAL_ROWS: 578 → 578\n",
      " Updating VIN: 4V4NC9EH5JN894425 → TOTAL_ROWS: 893 → 893\n",
      " Updating VIN: 4V4NC9EH5LN205325 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9EH5NN289777 → TOTAL_ROWS: 69 → 74\n",
      " Updating VIN: 4V4NC9EH6GN942846 → TOTAL_ROWS: 2063 → 2063\n",
      " Updating VIN: 4V4NC9EH7JN998821 → TOTAL_ROWS: 504 → 509\n",
      " Updating VIN: 4V4NC9EH7LN210218 → TOTAL_ROWS: 689 → 698\n",
      " Updating VIN: 4V4NC9EH8FN139017 → TOTAL_ROWS: 824 → 834\n",
      " Updating VIN: 4V4NC9EH8GN944498 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9EH8GN961902 → TOTAL_ROWS: 759 → 759\n",
      " Updating VIN: 4V4NC9EH8JN894497 → TOTAL_ROWS: 2204 → 2204\n",
      " Updating VIN: 4V4NC9EH9FN916966 → TOTAL_ROWS: 638 → 639\n",
      " Updating VIN: 4V4NC9EH9GN946633 → TOTAL_ROWS: 329 → 338\n",
      " Updating VIN: 4V4NC9EH9LN243320 → TOTAL_ROWS: 2064 → 2064\n",
      " Updating VIN: 4V4NC9EHXKN208073 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9EJ3FN918604 → TOTAL_ROWS: 2378 → 2378\n",
      " Updating VIN: 4V4NC9EJ3FN937685 → TOTAL_ROWS: 488 → 488\n",
      " Updating VIN: 4V4NC9EJ5GN935339 → TOTAL_ROWS: 359 → 359\n",
      " Updating VIN: 4V4NC9EJ5HN982498 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4NC9EJ8KN193057 → TOTAL_ROWS: 684 → 698\n",
      " Updating VIN: 4V4NC9EJXFN187833 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V4W19EG2KN216850 → TOTAL_ROWS: 698 → 699\n",
      " Updating VIN: 4V4WC9EG9MN295348 → TOTAL_ROWS: 804 → 818\n",
      " Updating VIN: 4V4WC9EH0MN600342 → TOTAL_ROWS: 2249 → 2249\n",
      " Updating VIN: 4V4WC9EH7MN276645 → TOTAL_ROWS: 29 → 29\n",
      " Updating VIN: 4V5KG9EH9LN251730 → TOTAL_ROWS: 449 → 449\n",
      " Updating VIN: 4V5KG9EJ5KN217477 → TOTAL_ROWS: 29 → 29\n",
      " Skipping VIN: 5 because it is invalid.\n",
      " Skipping VIN: ADTC-P because it is invalid.\n",
      " Skipping VIN: ADTS66 because it is invalid.\n",
      " Skipping VIN: AF because it is invalid.\n",
      " Skipping VIN: AME77 because it is invalid.\n",
      " Skipping VIN: CON because it is invalid.\n",
      " Skipping VIN: F-J because it is invalid.\n",
      " Skipping VIN: F-RUC because it is invalid.\n",
      " Skipping VIN: GY7KM008343 because it is invalid.\n",
      " Skipping VIN: H-200 because it is invalid.\n",
      " Skipping VIN: L-E because it is invalid.\n",
      " Skipping VIN: MA because it is invalid.\n",
      " Skipping VIN: MC because it is invalid.\n",
      " Skipping VIN: MUL because it is invalid.\n",
      " Skipping VIN: P-BAS1 because it is invalid.\n",
      " Skipping VIN: PLEV because it is invalid.\n",
      " Skipping VIN: PLS because it is invalid.\n",
      " Skipping VIN: PT because it is invalid.\n",
      " Skipping VIN: RAKE because it is invalid.\n",
      " Skipping VIN: RID because it is invalid.\n",
      " Skipping VIN: S because it is invalid.\n",
      " Skipping VIN: S1 because it is invalid.\n",
      " Skipping VIN: SA because it is invalid.\n",
      " Skipping VIN: SHAFT2 because it is invalid.\n",
      " Skipping VIN: SUSPL-E because it is invalid.\n",
      " Skipping VIN: T1 because it is invalid.\n",
      " Skipping VIN: U4ATP because it is invalid.\n",
      " Skipping VIN: ULINER because it is invalid.\n",
      " Skipping VIN: UXMC because it is invalid.\n",
      " Skipping VIN: WTDF22.5 because it is invalid.\n",
      "\n",
      " VINs_data.csv successfully updated. Total VINs: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of df_all_pop_VINs=322178, df_generated_pop_VINs = 85\n",
      "VIN=1M1AN2AY5LM001812 has TOTAL_ROWS=2084, which is < 2556 so partial...\n",
      "The submit command for the submitted job is: \n",
      "sbatch --account=vuh14_dibbs_sc --partition=sla-prio /storage/home/yqf5148/work/volvoPennState/Jobs/submit_partiallyCalculatedJobDone.sh 1M1AN2AY5LM001812 2084\n",
      "Job 36084542 submitted successfully.\n",
      "VIN=1M1AN4GY0MM022958 has TOTAL_ROWS=1914, which is < 2556 so partial...\n",
      "The submit command for the submitted job is: \n",
      "sbatch --account=vuh14_dibbs_sc --partition=sla-prio /storage/home/yqf5148/work/volvoPennState/Jobs/submit_partiallyCalculatedJobDone.sh 1M1AN4GY0MM022958 1914\n",
      "Job 36084543 submitted successfully.\n",
      "Hit the job limit (2) while processing partial VINs.\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n",
      "Some jobs are still running...\n",
      "{'36084542', '36084543'}\n"
     ]
    }
   ],
   "source": [
    "VINs_data_file_path = '/storage/home/yqf5148/work/volvoPennState/data/dataset/VINs_data.csv'\n",
    "resulted_data_path = '/storage/home/yqf5148/work/volvoPennState/data/dataset/resultedData.csv'\n",
    "\n",
    "# update_VINs_data_total_rows_from_resulted_data(VINs_data_file_path, resulted_data_path, headerList)\n",
    "update_VINs_data_from_resulted_data(VINs_data_file_path, resulted_data_path, headerList)\n",
    "\n",
    "\n",
    "df_all_pop_VINs = spark.sql('select distinct VIN from population')\n",
    "df_all_pop_VINs_p = df_all_pop_VINs.toPandas()\n",
    "\n",
    "# Read the VINs_data.csv (with header row: VIN,TOTAL_ROWS)\n",
    "df_generated_pop_VINs = pd.read_csv(\n",
    "    VINs_data_file_path, sep=',', names=['VIN','TOTAL_ROWS'],\n",
    "    header=None, dtype=str\n",
    ")\n",
    "\n",
    "print(f\"size of df_all_pop_VINs={len(df_all_pop_VINs_p)}, df_generated_pop_VINs = {len(df_generated_pop_VINs)}\")\n",
    "\n",
    "# Only proceed if the population has more VINs than the generated set\n",
    "if len(df_all_pop_VINs_p) > len(df_generated_pop_VINs):   \n",
    "\n",
    "    # Let this be your overall job limit\n",
    "    number_of_jobs = 2\n",
    "    jobs_submitted = 0\n",
    "    job_ids = []\n",
    "    output_files = []\n",
    "\n",
    "    try:\n",
    "        if len(df_generated_pop_VINs) > 0:\n",
    "            df_generated_pop_VINs['TOTAL_ROWS'] = df_generated_pop_VINs['TOTAL_ROWS'].astype(int)\n",
    "            processed_VINs = set(df_generated_pop_VINs['VIN'].astype(str))\n",
    "        else:\n",
    "            processed_VINs = set()\n",
    "    except FileNotFoundError:\n",
    "        print(\"VINs_data.csv not found. Starting fresh.\")\n",
    "        processed_VINs = set()\n",
    "\n",
    "    # --- 1) Process partially generated VINs (TOTAL_ROWS < 2556) --- The second condition is temporary\n",
    "    df_incomplete = df_generated_pop_VINs[df_generated_pop_VINs['TOTAL_ROWS'].between(999, 2557)]\n",
    "\n",
    "    \n",
    "    \n",
    "    for idx, row in df_incomplete.iterrows():\n",
    "        # If we've hit the limit, no more submissions\n",
    "        if jobs_submitted >= number_of_jobs:\n",
    "            break\n",
    "\n",
    "        thisVIN = row['VIN']\n",
    "        rows_val = row['TOTAL_ROWS']\n",
    "        print(f\"VIN={thisVIN} has TOTAL_ROWS={rows_val}, which is < 2556 so partial...\")\n",
    "\n",
    "        # Example usage: pass the last day as param\n",
    "        calendar_day_from_where_it_left_off = rows_val\n",
    "\n",
    "        # Submit partial job\n",
    "        df_filtered_population_for_this_VIN = df_all_pop_VINs.filter(f.col('VIN') == thisVIN)\n",
    "        script_path = \"/storage/home/yqf5148/work/volvoPennState/Jobs/submit_partiallyCalculatedJobDone.sh\"\n",
    "        output_file = f\"/storage/home/yqf5148/work/volvoPennState/Jobs/log_test/result_{thisVIN}.txt\"\n",
    "        job_id = submit_job2(script_path, thisVIN, calendar_day_from_where_it_left_off)\n",
    "\n",
    "        if job_id:\n",
    "            job_ids.append(job_id)\n",
    "            output_files.append(output_file)\n",
    "            processed_VINs.add(thisVIN)\n",
    "\n",
    "            # Overwrite VINs_data.csv entry with 0\n",
    "            new_VIN_entry = pd.DataFrame([[thisVIN, 0]], columns=['VIN','TOTAL_ROWS'])\n",
    "            new_VIN_entry.to_csv(VINs_data_file_path, mode='a', index=False, header=False)\n",
    "\n",
    "            jobs_submitted += 1\n",
    "\n",
    "    # If we've used up all jobs in partial VINs alone, we're done\n",
    "    if jobs_submitted >= number_of_jobs:\n",
    "        print(f\"Hit the job limit ({number_of_jobs}) while processing partial VINs.\")\n",
    "        check_jobs_status(job_ids)\n",
    "        get_jobs_output(output_files)\n",
    "        sys.exit(0)  # Or just return if in a function\n",
    "\n",
    "    # --- 2) Now do random selection for ungenerated VINs ---\n",
    "    # The code below remains the same, but includes a check so we don’t exceed the limit.\n",
    "    \n",
    "    total_VINs = len(df_all_pop_VINs_p)\n",
    "    print(f\"total_VINs: {total_VINs}\")\n",
    "\n",
    "    while jobs_submitted < number_of_jobs and len(processed_VINs) < total_VINs:\n",
    "        random_index = random.randint(0, total_VINs - 1)\n",
    "        print(f\"Random generated index in overall {total_VINs} VINs is {random_index}\")\n",
    "        row = df_all_pop_VINs_p.iloc[random_index]\n",
    "        thisVIN = str(row['VIN'])\n",
    "\n",
    "        if thisVIN in processed_VINs or whether_thisVIN_data_already_generated(thisVIN) == 1:\n",
    "            print(f\"This VIN = {thisVIN}'s data is already generated. Selecting a new one...\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"This VIN = {thisVIN}'s data is not generated.\")\n",
    "            df_filtered_population_for_this_VIN = df_all_pop_VINs.filter(f.col('VIN') == thisVIN)\n",
    "            script_path = \"/storage/home/yqf5148/work/volvoPennState/Jobs/submit.sh\"\n",
    "            output_file = f\"/storage/home/yqf5148/work/volvoPennState/Jobs/log_test/result_{thisVIN}.txt\"\n",
    "            job_id = submit_job1(script_path, thisVIN)\n",
    "\n",
    "            if job_id:\n",
    "                job_ids.append(job_id)\n",
    "                output_files.append(output_file)\n",
    "                processed_VINs.add(thisVIN)\n",
    "\n",
    "                # Append a new entry\n",
    "                new_VIN_entry = pd.DataFrame([[thisVIN, 0]], columns=['VIN','TOTAL_ROWS'])\n",
    "                new_VIN_entry.to_csv(VINs_data_file_path, mode='a', index=False, header=False)\n",
    "\n",
    "                jobs_submitted += 1\n",
    "\n",
    "            # Stop if we hit the limit\n",
    "            if jobs_submitted >= number_of_jobs:\n",
    "                print(f\"Hit the job limit ({number_of_jobs}) while picking random VINs.\")\n",
    "                break\n",
    "\n",
    "    # --- 3) Check job status & retrieve outputs ---\n",
    "    check_jobs_status(job_ids)\n",
    "    get_jobs_output(output_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f2de50-a8dd-4a6b-8e2b-62139374f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_pop_VINs_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volvopennstate_new_kernel",
   "language": "python",
   "name": "volvopennstate_new_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
