{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e04abb-b5c5-4926-a5f5-2520baf33f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVA_HOME=/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64\n",
      "env: PATH=/storage/home/yqf5148/work/anaconda3/envs/volvopennstate-env/bin:storage/icds/swst/deployed/production/20220813/apps/anaconda3/2021.05_gcc-8.5.0/bin:/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin\n"
     ]
    }
   ],
   "source": [
    "%env JAVA_HOME=/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64\n",
    "%env PATH=/storage/home/yqf5148/work/anaconda3/envs/volvopennstate-env/bin:storage/icds/swst/deployed/production/20220813/apps/anaconda3/2021.05_gcc-8.5.0/bin:/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59910f3-5b6a-4a75-9301-08538b354746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ps: /storage/icds/RISE/sw8/anaconda/anaconda3/envs/tensorflow/lib/libuuid.so.1: no version information available (required by /usr/lib64/libblkid.so.1)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/01 01:25:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/01 01:25:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/04/01 01:25:46 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/04/01 01:25:47 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark as psk\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# import submitit\n",
    "\n",
    "import time as t \n",
    "from datetime import date, datetime, timedelta\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from functools import reduce  \n",
    "from math import modf\n",
    "import sqlite3\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from delta import * \n",
    "from delta.tables import *\n",
    "from delta import configure_spark_with_delta_pip\n",
    "# import covalent as ct\n",
    "\n",
    "import subprocess\n",
    "import re\n",
    "import random\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# os.environ['PYDEVD_DISABLE_FILE_VALIDATION']=1\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "       .master(\"local[2]\") \\\n",
    "       .appName(\"MyApp\") \\\n",
    "       .config(\"spark.driver.maxResultSize\", \"20g\")\\\n",
    "       .config(\"spark.driver.memory\", \"100g\")\\\n",
    "       .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# sqlContext = SQLContext(sc)\n",
    "\n",
    "\n",
    "#both works\n",
    "# 1: \n",
    "# spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")    #To resolve the error for p1075_38 to_timestamp formating: You may get a different result due to the upgrading to Spark >= 3.0: Fail to parse '1/2/2019 20:40:00' in the new parser. You can set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0, or set to CORRECTED and treat it as an invalid datetime string.\n",
    "# Set Spark SQL legacy time parser policy to LEGACY to handle older date formats\n",
    "# 2:\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "# Increase the max fields in the string representation of a plan\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 1000)  # Increase to 1000 or more as needed\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"false\")\n",
    "\n",
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"/storage/home/yqf5148/work/volvoPennState/PopulationWithChassisId.csv\") \\\n",
    "          .createOrReplaceTempView(\"population\")\n",
    "\n",
    "df_population = spark.sql(\"SELECT * FROM population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a36fe2e-f879-4084-bd15-fd493863ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"/storage/home/yqf5148/work/volvoPennState/data/dataset/VINs_data.csv\") \\\n",
    "          .createOrReplaceTempView(\"VINs_data\")\n",
    "\n",
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"/storage/home/yqf5148/work/volvoPennState/PopulationWithChassisId.csv\") \\\n",
    "          .createOrReplaceTempView(\"population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28af062b-35e6-4641-8e08-6784fc299a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "headerList = [    \n",
    "          \"calendar_day\", \n",
    "          \"f_1_dtc38_1th_15d\", \n",
    "          \"f_1_dtc38_2nd_15d\", \n",
    "          \"f_2_dtc38_1th_15d\", \n",
    "          \"f_2_dtc38_2nd_15d\", \n",
    "          \"f_3_dtc38_1th_15d\", \n",
    "          \"f_3_dtc38_2nd_15d\", \n",
    "          \"f_4_dtc38_1th_15d\", \n",
    "          \"f_4_dtc38_2nd_15d\", \n",
    "          \"f_5_dtc38_1th_15d\", \n",
    "          \"f_5_dtc38_2nd_15d\", \n",
    "          \"f_6_dtc38_1th_15d\", \n",
    "          \"f_6_dtc38_2nd_15d\", \n",
    "          \"f_7_dtc38_1th_15d\", \n",
    "          \"f_7_dtc38_2nd_15d\", \n",
    "          \"f_8_dtc38_1th_15d\", \n",
    "          \"f_8_dtc38_2nd_15d\", \n",
    "\n",
    "          \"f_1_dtc75_1th_15d\", \n",
    "          \"f_1_dtc75_2nd_15d\", \n",
    "          \"f_2_dtc75_1th_15d\", \n",
    "          \"f_2_dtc75_2nd_15d\", \n",
    "          \"f_3_dtc75_1th_15d\", \n",
    "          \"f_3_dtc75_2nd_15d\", \n",
    "          \"f_4_dtc75_1th_15d\", \n",
    "          \"f_4_dtc75_2nd_15d\", \n",
    "          \"f_5_dtc75_1th_15d\", \n",
    "          \"f_5_dtc75_2nd_15d\", \n",
    "          \"f_6_dtc75_1th_15d\", \n",
    "          \"f_6_dtc75_2nd_15d\", \n",
    "          \"f_7_dtc75_1th_15d\", \n",
    "          \"f_7_dtc75_2nd_15d\", \n",
    "          \"f_8_dtc75_1th_15d\", \n",
    "          \"f_8_dtc75_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc77_1th_15d\", \n",
    "          \"f_1_dtc77_2nd_15d\", \n",
    "          \"f_2_dtc77_1th_15d\", \n",
    "          \"f_2_dtc77_2nd_15d\", \n",
    "          \"f_3_dtc77_1th_15d\", \n",
    "          \"f_3_dtc77_2nd_15d\", \n",
    "          \"f_4_dtc77_1th_15d\", \n",
    "          \"f_4_dtc77_2nd_15d\", \n",
    "          \"f_5_dtc77_1th_15d\", \n",
    "          \"f_5_dtc77_2nd_15d\", \n",
    "          \"f_6_dtc77_1th_15d\", \n",
    "          \"f_6_dtc77_2nd_15d\", \n",
    "          \"f_7_dtc77_1th_15d\", \n",
    "          \"f_7_dtc77_2nd_15d\", \n",
    "          \"f_8_dtc77_1th_15d\", \n",
    "          \"f_8_dtc77_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc86_1th_15d\", \n",
    "          \"f_1_dtc86_2nd_15d\", \n",
    "          \"f_2_dtc86_1th_15d\", \n",
    "          \"f_2_dtc86_2nd_15d\", \n",
    "          \"f_3_dtc86_1th_15d\", \n",
    "          \"f_3_dtc86_2nd_15d\", \n",
    "          \"f_4_dtc86_1th_15d\", \n",
    "          \"f_4_dtc86_2nd_15d\", \n",
    "          \"f_5_dtc86_1th_15d\", \n",
    "          \"f_5_dtc86_2nd_15d\", \n",
    "          \"f_6_dtc86_1th_15d\", \n",
    "          \"f_6_dtc86_2nd_15d\", \n",
    "          \"f_7_dtc86_1th_15d\", \n",
    "          \"f_7_dtc86_2nd_15d\", \n",
    "          \"f_8_dtc86_1th_15d\", \n",
    "          \"f_8_dtc86_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc92_1th_15d\", \n",
    "          \"f_1_dtc92_2nd_15d\", \n",
    "          \"f_2_dtc92_1th_15d\", \n",
    "          \"f_2_dtc92_2nd_15d\", \n",
    "          \"f_3_dtc92_1th_15d\", \n",
    "          \"f_3_dtc92_2nd_15d\", \n",
    "          \"f_4_dtc92_1th_15d\", \n",
    "          \"f_4_dtc92_2nd_15d\", \n",
    "          \"f_5_dtc92_1th_15d\", \n",
    "          \"f_5_dtc92_2nd_15d\", \n",
    "          \"f_6_dtc92_1th_15d\", \n",
    "          \"f_6_dtc92_2nd_15d\", \n",
    "          \"f_7_dtc92_1th_15d\", \n",
    "          \"f_7_dtc92_2nd_15d\", \n",
    "          \"f_8_dtc92_1th_15d\", \n",
    "          \"f_8_dtc92_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc94_1th_15d\", \n",
    "          \"f_1_dtc94_2nd_15d\", \n",
    "          \"f_2_dtc94_1th_15d\", \n",
    "          \"f_2_dtc94_2nd_15d\", \n",
    "          \"f_3_dtc94_1th_15d\", \n",
    "          \"f_3_dtc94_2nd_15d\", \n",
    "          \"f_4_dtc94_1th_15d\", \n",
    "          \"f_4_dtc94_2nd_15d\", \n",
    "          \"f_5_dtc94_1th_15d\", \n",
    "          \"f_5_dtc94_2nd_15d\", \n",
    "          \"f_6_dtc94_1th_15d\", \n",
    "          \"f_6_dtc94_2nd_15d\", \n",
    "          \"f_7_dtc94_1th_15d\", \n",
    "          \"f_7_dtc94_2nd_15d\", \n",
    "          \"f_8_dtc94_1th_15d\", \n",
    "          \"f_8_dtc94_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc0401_1th_15d\", \n",
    "          \"f_1_dtc0401_2nd_15d\", \n",
    "          \"f_2_dtc0401_1th_15d\", \n",
    "          \"f_2_dtc0401_2nd_15d\", \n",
    "          \"f_3_dtc0401_1th_15d\", \n",
    "          \"f_3_dtc0401_2nd_15d\", \n",
    "          \"f_4_dtc0401_1th_15d\", \n",
    "          \"f_4_dtc0401_2nd_15d\", \n",
    "          \"f_5_dtc0401_1th_15d\", \n",
    "          \"f_5_dtc0401_2nd_15d\", \n",
    "          \"f_6_dtc0401_1th_15d\", \n",
    "          \"f_6_dtc0401_2nd_15d\", \n",
    "          \"f_7_dtc0401_1th_15d\", \n",
    "          \"f_7_dtc0401_2nd_15d\", \n",
    "          \"f_8_dtc0401_1th_15d\", \n",
    "          \"f_8_dtc0401_2nd_15d\",\n",
    "\n",
    "\n",
    "          \"f_1_dtc2457_1th_15d\", \n",
    "          \"f_1_dtc2457_2nd_15d\", \n",
    "          \"f_2_dtc2457_1th_15d\", \n",
    "          \"f_2_dtc2457_2nd_15d\", \n",
    "          \"f_3_dtc2457_1th_15d\", \n",
    "          \"f_3_dtc2457_2nd_15d\", \n",
    "          \"f_4_dtc2457_1th_15d\", \n",
    "          \"f_4_dtc2457_2nd_15d\", \n",
    "          \"f_5_dtc2457_1th_15d\", \n",
    "          \"f_5_dtc2457_2nd_15d\", \n",
    "          \"f_6_dtc2457_1th_15d\", \n",
    "          \"f_6_dtc2457_2nd_15d\", \n",
    "          \"f_7_dtc2457_1th_15d\", \n",
    "          \"f_7_dtc2457_2nd_15d\", \n",
    "          \"f_8_dtc2457_1th_15d\", \n",
    "          \"f_8_dtc2457_2nd_15d\",\n",
    "\n",
    "          \"if_parts_replaced_in_1th_15d\", \n",
    "          \"if_parts_replaced_in_2nd_15d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a89d55f0-3058-49ce-8c21-02d35877e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_vin(vin: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns 1 if the VIN is valid, 0 if not.\n",
    "    A valid VIN is exactly 17 characters long and does not contain I, O, or Q.\n",
    "    \"\"\"\n",
    "    vin = vin.strip().upper()\n",
    "\n",
    "    # Rule 1: VIN must be exactly 17 characters\n",
    "    if len(vin) != 17:\n",
    "        return 0\n",
    "\n",
    "    # Rule 2: Must only contain A-H, J-N, P, R-Z, and 0-9 (excluding I, O, Q)\n",
    "    if not re.match(\"^[A-HJ-NPR-Z0-9]{17}$\", vin):\n",
    "        return 0\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbaabcc9-f5d8-4fa1-b41b-ba0c916b99de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1062966/3116708125.py:13: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_resulted = pd.read_csv(resulted_data_path, names=all_columns_names, header=None, on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Skipping VIN: -AGS because it is invalid.\n",
      " Skipping VIN: -ST because it is invalid.\n",
      " Skipping VIN: .0 because it is invalid.\n",
      " Skipping VIN: 0 because it is invalid.\n",
      " Skipping VIN: 0.0 because it is invalid.\n",
      " Skipping VIN: 1 because it is invalid.\n",
      " Adding new VIN: 1M1AN07Y3GM021042 → TOTAL_ROWS: 414\n",
      " Adding new VIN: 1M1AN2AY5LM001812 → TOTAL_ROWS: 2084\n",
      " Adding new VIN: 1M1AN2GY3KM006268 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M1AN3GY4LM019358 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M1AN4GY0MM022958 → TOTAL_ROWS: 1914\n",
      " Adding new VIN: 1M1AN4GY0MM022961 → TOTAL_ROWS: 2339\n",
      " Adding new VIN: 1M1AN4GY7KM008343 → TOTAL_ROWS: 779\n",
      " Adding new VIN: 1M1AN4GY8MM021279 → TOTAL_ROWS: 2199\n",
      " Adding new VIN: 1M1AN4GYXLM018348 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M1AW01Y2FM006911 → TOTAL_ROWS: 1433\n",
      " Adding new VIN: 1M1AW01Y5JM010413 → TOTAL_ROWS: 24\n",
      " Adding new VIN: 1M1AW02Y1FM050302 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M1AW02Y7FM051728 → TOTAL_ROWS: 764\n",
      " Adding new VIN: 1M1AW07Y4FM045037 → TOTAL_ROWS: 68\n",
      " Adding new VIN: 1M2AU02C6GM010563 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M2AU04C5FM008959 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M2AV02C5JM018223 → TOTAL_ROWS: 2139\n",
      " Adding new VIN: 1M2AV02C6HM016569 → TOTAL_ROWS: 2244\n",
      " Adding new VIN: 1M2AX04C3GM030029 → TOTAL_ROWS: 743\n",
      " Adding new VIN: 1M2AX04C7GM027070 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M2AX04C9HM034281 → TOTAL_ROWS: 1964\n",
      " Adding new VIN: 1M2AX07C0HM032978 → TOTAL_ROWS: 374\n",
      " Adding new VIN: 1M2AX07C7FM024311 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M2AX13C1GM035012 → TOTAL_ROWS: 624\n",
      " Adding new VIN: 1M2AX13C3HM037068 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M2AX13C4GM031245 → TOTAL_ROWS: 719\n",
      " Adding new VIN: 1M2AX13C4JM040440 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M2AX13C9FM027402 → TOTAL_ROWS: 2108\n",
      " Adding new VIN: 1M2GR2GC1LM015017 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M2GR2GC2MM025105 → TOTAL_ROWS: 1979\n",
      " Adding new VIN: 1M2GR2GC6LM012730 → TOTAL_ROWS: 719\n",
      " Adding new VIN: 1M2GR3GC2MM022467 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M2GR4GC0LM014601 → TOTAL_ROWS: 684\n",
      " Adding new VIN: 1M2GR4GC0LM018549 → TOTAL_ROWS: 2198\n",
      " Adding new VIN: 1M2GR4GC8LM017763 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M2GR4GCXKM004284 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 1M2LR05C3HM001875 → TOTAL_ROWS: 788\n",
      " Adding new VIN: 1M2TE2GC1LM003511 → TOTAL_ROWS: 2079\n",
      " Skipping VIN: 2B because it is invalid.\n",
      " Skipping VIN: 3 because it is invalid.\n",
      " Adding new VIN: 4V4M19EH8FN184640 → TOTAL_ROWS: 1479\n",
      " Adding new VIN: 4V4MC9EG6FN178787 → TOTAL_ROWS: 2054\n",
      " Adding new VIN: 4V4N19EH5LN221692 → TOTAL_ROWS: 794\n",
      " Adding new VIN: 4V4N99EH3HN975934 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9DH1KN205824 → TOTAL_ROWS: 24\n",
      " Adding new VIN: 4V4NC9EH0GN960694 → TOTAL_ROWS: 759\n",
      " Adding new VIN: 4V4NC9EH0HN991459 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9EH0LN264590 → TOTAL_ROWS: 2138\n",
      " Adding new VIN: 4V4NC9EH1FN911535 → TOTAL_ROWS: 728\n",
      " Adding new VIN: 4V4NC9EH1FN933289 → TOTAL_ROWS: 1013\n",
      " Adding new VIN: 4V4NC9EH1GN938316 → TOTAL_ROWS: 2168\n",
      " Adding new VIN: 4V4NC9EH1GN973065 → TOTAL_ROWS: 24\n",
      " Adding new VIN: 4V4NC9EH2FN919420 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9EH2LN238489 → TOTAL_ROWS: 728\n",
      " Adding new VIN: 4V4NC9EH2NN289266 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9EH4GN952713 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9EH4HN977144 → TOTAL_ROWS: 2124\n",
      " Adding new VIN: 4V4NC9EH4JN887837 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9EH4JN893072 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9EH4JN998906 → TOTAL_ROWS: 2124\n",
      " Adding new VIN: 4V4NC9EH5HN990971 → TOTAL_ROWS: 578\n",
      " Adding new VIN: 4V4NC9EH5JN894425 → TOTAL_ROWS: 893\n",
      " Adding new VIN: 4V4NC9EH5LN205325 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9EH5NN289777 → TOTAL_ROWS: 69\n",
      " Adding new VIN: 4V4NC9EH6GN942846 → TOTAL_ROWS: 2063\n",
      " Adding new VIN: 4V4NC9EH7JN998821 → TOTAL_ROWS: 504\n",
      " Adding new VIN: 4V4NC9EH7LN210218 → TOTAL_ROWS: 689\n",
      " Adding new VIN: 4V4NC9EH8FN139017 → TOTAL_ROWS: 824\n",
      " Adding new VIN: 4V4NC9EH8GN944498 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9EH8GN961902 → TOTAL_ROWS: 759\n",
      " Adding new VIN: 4V4NC9EH8JN894497 → TOTAL_ROWS: 2204\n",
      " Adding new VIN: 4V4NC9EH9FN916966 → TOTAL_ROWS: 638\n",
      " Adding new VIN: 4V4NC9EH9GN946633 → TOTAL_ROWS: 329\n",
      " Adding new VIN: 4V4NC9EH9LN243320 → TOTAL_ROWS: 2064\n",
      " Adding new VIN: 4V4NC9EHXKN208073 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9EJ3FN918604 → TOTAL_ROWS: 2378\n",
      " Adding new VIN: 4V4NC9EJ3FN937685 → TOTAL_ROWS: 488\n",
      " Adding new VIN: 4V4NC9EJ5GN935339 → TOTAL_ROWS: 359\n",
      " Adding new VIN: 4V4NC9EJ5HN982498 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4NC9EJ8KN193057 → TOTAL_ROWS: 684\n",
      " Adding new VIN: 4V4NC9EJXFN187833 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V4W19EG2KN216850 → TOTAL_ROWS: 698\n",
      " Adding new VIN: 4V4WC9EG9MN295348 → TOTAL_ROWS: 804\n",
      " Adding new VIN: 4V4WC9EH0MN600342 → TOTAL_ROWS: 2249\n",
      " Adding new VIN: 4V4WC9EH7MN276645 → TOTAL_ROWS: 29\n",
      " Adding new VIN: 4V5KG9EH9LN251730 → TOTAL_ROWS: 449\n",
      " Adding new VIN: 4V5KG9EJ5KN217477 → TOTAL_ROWS: 29\n",
      " Skipping VIN: 5 because it is invalid.\n",
      " Skipping VIN: ADTC-P because it is invalid.\n",
      " Skipping VIN: ADTS66 because it is invalid.\n",
      " Skipping VIN: AF because it is invalid.\n",
      " Skipping VIN: AME77 because it is invalid.\n",
      " Skipping VIN: CON because it is invalid.\n",
      " Skipping VIN: F-J because it is invalid.\n",
      " Skipping VIN: F-RUC because it is invalid.\n",
      " Skipping VIN: GY7KM008343 because it is invalid.\n",
      " Skipping VIN: H-200 because it is invalid.\n",
      " Skipping VIN: L-E because it is invalid.\n",
      " Skipping VIN: MA because it is invalid.\n",
      " Skipping VIN: MC because it is invalid.\n",
      " Skipping VIN: MUL because it is invalid.\n",
      " Skipping VIN: P-BAS1 because it is invalid.\n",
      " Skipping VIN: PLEV because it is invalid.\n",
      " Skipping VIN: PLS because it is invalid.\n",
      " Skipping VIN: PT because it is invalid.\n",
      " Skipping VIN: RAKE because it is invalid.\n",
      " Skipping VIN: RID because it is invalid.\n",
      " Skipping VIN: S because it is invalid.\n",
      " Skipping VIN: S1 because it is invalid.\n",
      " Skipping VIN: SA because it is invalid.\n",
      " Skipping VIN: SHAFT2 because it is invalid.\n",
      " Skipping VIN: SUSPL-E because it is invalid.\n",
      " Skipping VIN: T1 because it is invalid.\n",
      " Skipping VIN: U4ATP because it is invalid.\n",
      " Skipping VIN: ULINER because it is invalid.\n",
      " Skipping VIN: UXMC because it is invalid.\n",
      " Skipping VIN: WTDF22.5 because it is invalid.\n",
      "\n",
      " VINs_data.csv successfully updated. Total VINs: 85\n"
     ]
    }
   ],
   "source": [
    "# Input paths\n",
    "VINs_data_file_path = '/storage/home/yqf5148/work/volvoPennState/data/dataset/VINs_data.csv'\n",
    "resulted_data_path = '/storage/home/yqf5148/work/volvoPennState/data/dataset/resultedData.csv'\n",
    "\n",
    "# Columns: Keep selected + headers\n",
    "selected_features_from_population = ['VIN', 'ENGINE_SIZE', 'ENGINE_HP', 'VEH_TYPE'] + [s for s in df_population.columns if 'KOLA' in s]\n",
    "all_columns_names = selected_features_from_population + headerList\n",
    "\n",
    "# 🔹 Step 1: Load VINs_data.csv\n",
    "df_vins = pd.read_csv(VINs_data_file_path, names=[\"VIN\", \"TOTAL_ROWS\"], dtype={\"VIN\": str, \"TOTAL_ROWS\": int}, header=None)\n",
    "\n",
    "# 🔹 Step 2: Load resultedData.csv (skip bad lines)\n",
    "df_resulted = pd.read_csv(resulted_data_path, names=all_columns_names, header=None, on_bad_lines='skip')\n",
    "\n",
    "# 🔹 Step 3: Convert calendar_day to numeric\n",
    "df_resulted[\"calendar_day\"] = pd.to_numeric(df_resulted[\"calendar_day\"], errors='coerce')\n",
    "\n",
    "# 🔹 Step 4: Group by VIN → max calendar_day\n",
    "grouped = df_resulted.groupby(\"VIN\")[\"calendar_day\"].max().reset_index()\n",
    "grouped.columns = [\"VIN\", \"MAX_CALENDAR_DAY\"]\n",
    "\n",
    "# 🔹 Step 5: Build dictionary of existing VINs\n",
    "vins_dict = dict(zip(df_vins[\"VIN\"], df_vins[\"TOTAL_ROWS\"]))\n",
    "\n",
    "# 🔹 Step 6: Update or add VINs\n",
    "updated_rows = []\n",
    "\n",
    "for _, row in grouped.iterrows():\n",
    "    vin = row[\"VIN\"]\n",
    "    max_day_val = row[\"MAX_CALENDAR_DAY\"]\n",
    "\n",
    "    if(is_valid_vin(vin)==0):\n",
    "        print(f\" Skipping VIN: {vin} because it is invalid.\")\n",
    "        continue\n",
    "        \n",
    "    if pd.isna(max_day_val):\n",
    "        print(f\" Skipping VIN: {vin} → MAX_CALENDAR_DAY is NaN\")\n",
    "        continue\n",
    "\n",
    "    max_day = int(max_day_val)\n",
    "\n",
    "    if vin in vins_dict:\n",
    "        print(f\" Updating VIN: {vin} → TOTAL_ROWS: {vins_dict[vin]} → {max_day}\")\n",
    "    else:\n",
    "        print(f\" Adding new VIN: {vin} → TOTAL_ROWS: {max_day}\")\n",
    "\n",
    "    updated_rows.append([vin, max_day])\n",
    "\n",
    "# 🔹 Step 7: Add VINs from original not in grouped\n",
    "existing_vins_set = set(grouped[\"VIN\"])\n",
    "for vin, total_rows in vins_dict.items():\n",
    "    if vin not in existing_vins_set:\n",
    "        updated_rows.append([vin, total_rows])\n",
    "        print(f\" Keeping existing VIN: {vin} → TOTAL_ROWS: {total_rows}\")\n",
    "\n",
    "# 🔹 Step 8: Save updated VINs\n",
    "df_final = pd.DataFrame(updated_rows, columns=[\"VIN\", \"TOTAL_ROWS\"])\n",
    "df_final.to_csv(VINs_data_file_path, index=False, header=False)\n",
    "\n",
    "print(f\"\\n VINs_data.csv successfully updated. Total VINs: {len(df_final)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dd7bc5-d7d9-42c8-a17e-7504d34c73a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volvopennstate_new_kernel",
   "language": "python",
   "name": "volvopennstate_new_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
