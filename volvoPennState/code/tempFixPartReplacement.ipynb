{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c98eb3-17ce-4265-9e85-3e7aac964ecf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVA_HOME=/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64\n",
      "env: PATH=/storage/home/yqf5148/work/anaconda3/envs/volvopennstate-env/bin:storage/icds/swst/deployed/production/20220813/apps/anaconda3/2021.05_gcc-8.5.0/bin:/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin\n"
     ]
    }
   ],
   "source": [
    "%env JAVA_HOME=/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64\n",
    "%env PATH=/storage/home/yqf5148/work/anaconda3/envs/volvopennstate-env/bin:storage/icds/swst/deployed/production/20220813/apps/anaconda3/2021.05_gcc-8.5.0/bin:/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin:/storage/icds/tools/bin:/storage/sys/slurm/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d68afada-a714-4a4e-840a-04e0c7523ae2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ps: /storage/icds/RISE/sw8/anaconda/anaconda3/envs/tensorflow/lib/libuuid.so.1: no version information available (required by /usr/lib64/libblkid.so.1)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/13 19:50:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pyspark as psk\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "\n",
    "import time as t \n",
    "from datetime import date, datetime, timedelta\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from functools import reduce  \n",
    "from math import modf\n",
    "import sqlite3\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from delta import * \n",
    "from delta.tables import *\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from IPython import get_ipython\n",
    "import csv\n",
    "\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "conf = (SparkConf().set(\"spark.driver.maxResultSize\", \"4g\"))\n",
    "\n",
    "# Create new context\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "\n",
    "# sc = SparkContext(\"local\", \"Simple App\")\n",
    "\n",
    "# Create SparkSession \n",
    "spark = SparkSession.builder \\\n",
    "       .master(\"local[2]\") \\\n",
    "       .appName(\"test\") \\\n",
    "       .config(\"spark.driver.maxResultSize\", \"20g\")\\\n",
    "       .config(\"spark.driver.memory\", \"100g\")\\\n",
    "       .getOrCreate()\n",
    "\n",
    "#both works\n",
    "# 1: \n",
    "# spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")    #To resolve the error for p1075_38 to_timestamp formating: You may get a different result due to the upgrading to Spark >= 3.0: Fail to parse '1/2/2019 20:40:00' in the new parser. You can set spark.sql.legacy.timeParserPolicy to LEGACY to restore the behavior before Spark 3.0, or set to CORRECTED and treat it as an invalid datetime string.\n",
    "# Set Spark SQL legacy time parser policy to LEGACY to handle older date formats\n",
    "# 2:\n",
    "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "# Increase the max fields in the string representation of a plan\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 1000)  # Increase to 1000 or more as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3b431-0b8b-4263-93d4-61c78580bd09",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"/storage/home/yqf5148/work/volvoPennState/data/dataset/VINs_data_part_repl.csv\") \\\n",
    "          .createOrReplaceTempView(\"VINs_data1\")\n",
    "\n",
    "# spark.read.option(\"header\",True) \\\n",
    "#           .csv(\"/storage/home/yqf5148/work/volvoPennState/PopulationWithChassisId.csv\") \\\n",
    "#           .createOrReplaceTempView(\"population\")\n",
    "\n",
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"/storage/home/yqf5148/work/volvoPennState/CCA Claims.csv\") \\\n",
    "          .createOrReplaceTempView(\"cca_claims\")\n",
    "\n",
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"/storage/home/yqf5148/work/volvoPennState/EGR Cooler Claims.csv\") \\\n",
    "          .createOrReplaceTempView(\"egr_cooler_claims\")\n",
    "\n",
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"/storage/home/yqf5148/work/volvoPennState/EGR FG 293 Claims.csv\") \\\n",
    "          .createOrReplaceTempView(\"egr_fg_293_claims\")\n",
    "\n",
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"/storage/home/yqf5148/work/volvoPennState/EGR Sensors.csv\") \\\n",
    "          .createOrReplaceTempView(\"egr_sensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b3030-5f4f-4c34-863a-efdd21af7c4f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def if_part_is_replaced_for_this_VIN_in_this_timespan(thisVIN, start_date, end_date):\n",
    "#     fault_date_time_format = 'M/d/yyyy'\n",
    "    \n",
    "#     # Loading all claims tables for the specific VIN\n",
    "#     df_cca_claims = spark.sql(f\"SELECT * FROM cca_claims WHERE VIN = '{thisVIN}'\")\n",
    "#     df_egr_cooler_claims = spark.sql(f\"SELECT * FROM egr_cooler_claims WHERE VIN = '{thisVIN}'\")\n",
    "#     df_egr_fg_293_claims = spark.sql(f\"SELECT * FROM egr_fg_293_claims WHERE VIN = '{thisVIN}'\")\n",
    "#     df_egr_sensors_claims = spark.sql(f\"SELECT * FROM egr_sensors WHERE VIN = '{thisVIN}'\")\n",
    "    \n",
    "#     # Define filtering condition\n",
    "#     filter_condition = (\n",
    "#         (f.to_timestamp(f.col('CLAIM_REG_DATE'), fault_date_time_format) > f.to_timestamp(f.lit(start_date), fault_date_time_format)) &\n",
    "#         (f.to_timestamp(f.col('CLAIM_REG_DATE'), fault_date_time_format) < f.to_timestamp(f.lit(end_date), fault_date_time_format)) &\n",
    "#         (f.col('TOT_CLAIM_PAYMENT_USD') > 1000.0)\n",
    "#     )\n",
    "    \n",
    "#     # Filter dataframes based on the condition\n",
    "#     df_cca_claims_part_replacements = df_cca_claims.filter(filter_condition)\n",
    "#     df_egr_cooler_claims_part_replacements = df_egr_cooler_claims.filter(filter_condition)\n",
    "#     df_egr_fg_293_claims_part_replacements = df_egr_fg_293_claims.filter(filter_condition)\n",
    "#     df_egr_sensors_claims_part_replacements = df_egr_sensors_claims.filter(filter_condition)\n",
    "    \n",
    "#     # Count replacements in each table\n",
    "#     total_replacements = (\n",
    "#         df_cca_claims_part_replacements.count() +\n",
    "#         df_egr_cooler_claims_part_replacements.count() +\n",
    "#         df_egr_fg_293_claims_part_replacements.count() +\n",
    "#         df_egr_sensors_claims_part_replacements.count()\n",
    "#     )\n",
    "    \n",
    "#     return 1 if total_replacements > 0 else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35e11f-8b0e-4cd2-b9dd-728837b6111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def if_part_is_replaced_for_this_VIN_in_this_timespan(thisVIN, start_date, end_date):\n",
    "\n",
    "    # Initialize an empty list to store the results\n",
    "    replacement_records = []\n",
    "\n",
    "    fault_date_time_format = 'MM/dd/yyyy'\n",
    "    start_date = '2014-12-31'\n",
    "    end_date = '2021-12-31'\n",
    "\n",
    "    # Load all claims tables for the specific VIN\n",
    "    claims_datasets = {\n",
    "        'cca_claims': f\"SELECT VIN, CLAIM_REG_DATE, TOT_CLAIM_PAYMENT_USD FROM cca_claims WHERE VIN = '{thisVIN}'\",\n",
    "        'egr_cooler_claims': f\"SELECT VIN, CLAIM_REG_DATE, TOT_CLAIM_PAYMENT_USD FROM egr_cooler_claims WHERE VIN = '{thisVIN}'\",\n",
    "        'egr_fg_293_claims': f\"SELECT VIN, CLAIM_REG_DATE, TOT_CLAIM_PAYMENT_USD FROM egr_fg_293_claims WHERE VIN = '{thisVIN}'\",\n",
    "        'egr_sensors_claims': f\"SELECT VIN, CLAIM_REG_DATE, TOT_CLAIM_PAYMENT_USD FROM egr_sensors WHERE VIN = '{thisVIN}'\"\n",
    "    }\n",
    "\n",
    "    # Define filtering condition with corrected date format\n",
    "    for dataset_name, query in claims_datasets.items():\n",
    "        try:\n",
    "            df_claims = spark.sql(query)\n",
    "\n",
    "            if df_claims is not None and df_claims.count() > 0:\n",
    "\n",
    "                # df_claims.printSchema()  # Debugging step\n",
    "                # df_claims.show(5, truncate=False)  # Show sample data\n",
    "\n",
    "                df_claims = df_claims.withColumn(\"CLAIM_REG_DATE\", f.to_date(f.col(\"CLAIM_REG_DATE\"), \"MM/dd/yyyy\"))\n",
    "\n",
    "                # Try alternative filtering\n",
    "                df_filtered = df_claims.filter(\n",
    "                    (f.col('CLAIM_REG_DATE') >= f.to_date(f.lit(start_date), \"yyyy-MM-dd\")) &\n",
    "                    (f.col('CLAIM_REG_DATE') <= f.to_date(f.lit(end_date), \"yyyy-MM-dd\")) &\n",
    "                    (f.col('TOT_CLAIM_PAYMENT_USD') > 1000.0)\n",
    "                )\n",
    "\n",
    "                # df_filtered.show(5, truncate=False)  # Show filtered data\n",
    "\n",
    "                if df_filtered is not None and df_filtered.count() > 0:\n",
    "                    for row in df_filtered.collect():\n",
    "                        replacement_records.append([thisVIN, dataset_name, row['CLAIM_REG_DATE'], row['TOT_CLAIM_PAYMENT_USD']])\n",
    "\n",
    "        except AnalysisException as e:\n",
    "            print(f\"Error processing dataset {dataset_name} for VIN {thisVIN}: {e}\")\n",
    "\n",
    "\n",
    "        if replacement_records:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "babb1e15-d037-4d2a-9cb4-425939c3e55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIN</th>\n",
       "      <th>ENGINE_SIZE</th>\n",
       "      <th>ENGINE_HP</th>\n",
       "      <th>VEH_TYPE</th>\n",
       "      <th>_KOLA_01X</th>\n",
       "      <th>_KOLA_02X</th>\n",
       "      <th>_KOLA_03X</th>\n",
       "      <th>_KOLA_04X</th>\n",
       "      <th>_KOLA_05X</th>\n",
       "      <th>_KOLA_06X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_5_dtc2457_1th_15d</th>\n",
       "      <th>f_5_dtc2457_2nd_15d</th>\n",
       "      <th>f_6_dtc2457_1th_15d</th>\n",
       "      <th>f_6_dtc2457_2nd_15d</th>\n",
       "      <th>f_7_dtc2457_1th_15d</th>\n",
       "      <th>f_7_dtc2457_2nd_15d</th>\n",
       "      <th>f_8_dtc2457_1th_15d</th>\n",
       "      <th>f_8_dtc2457_2nd_15d</th>\n",
       "      <th>if_parts_replaced_in_1th_15d</th>\n",
       "      <th>if_parts_replaced_in_2nd_15d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4V4NC9EH6KN904736</td>\n",
       "      <td>D13</td>\n",
       "      <td>455</td>\n",
       "      <td>VNL</td>\n",
       "      <td>WTDF22.5</td>\n",
       "      <td>WTDD22.5</td>\n",
       "      <td>UWTDT</td>\n",
       "      <td>WBF-ALCO</td>\n",
       "      <td>WBD-ALCO</td>\n",
       "      <td>UWBT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4V4NC9EH6KN904736</td>\n",
       "      <td>D13</td>\n",
       "      <td>455</td>\n",
       "      <td>VNL</td>\n",
       "      <td>WTDF22.5</td>\n",
       "      <td>WTDD22.5</td>\n",
       "      <td>UWTDT</td>\n",
       "      <td>WBF-ALCO</td>\n",
       "      <td>WBD-ALCO</td>\n",
       "      <td>UWBT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4V4NC9EH6KN904736</td>\n",
       "      <td>D13</td>\n",
       "      <td>455</td>\n",
       "      <td>VNL</td>\n",
       "      <td>WTDF22.5</td>\n",
       "      <td>WTDD22.5</td>\n",
       "      <td>UWTDT</td>\n",
       "      <td>WBF-ALCO</td>\n",
       "      <td>WBD-ALCO</td>\n",
       "      <td>UWBT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4V4NC9EH6KN904736</td>\n",
       "      <td>D13</td>\n",
       "      <td>455</td>\n",
       "      <td>VNL</td>\n",
       "      <td>WTDF22.5</td>\n",
       "      <td>WTDD22.5</td>\n",
       "      <td>UWTDT</td>\n",
       "      <td>WBF-ALCO</td>\n",
       "      <td>WBD-ALCO</td>\n",
       "      <td>UWBT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4V4NC9EH6KN904736</td>\n",
       "      <td>D13</td>\n",
       "      <td>455</td>\n",
       "      <td>VNL</td>\n",
       "      <td>WTDF22.5</td>\n",
       "      <td>WTDD22.5</td>\n",
       "      <td>UWTDT</td>\n",
       "      <td>WBF-ALCO</td>\n",
       "      <td>WBD-ALCO</td>\n",
       "      <td>UWBT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788694</th>\n",
       "      <td>4V4NC9EG9LN267768</td>\n",
       "      <td>D13</td>\n",
       "      <td>405</td>\n",
       "      <td>VNL</td>\n",
       "      <td>WTDF22.5</td>\n",
       "      <td>WTDD22.5</td>\n",
       "      <td>UWTDT</td>\n",
       "      <td>WBF-ACCU</td>\n",
       "      <td>WBD-ACCU</td>\n",
       "      <td>UWBT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788695</th>\n",
       "      <td>4V4NC9EG9LN267768</td>\n",
       "      <td>D13</td>\n",
       "      <td>405</td>\n",
       "      <td>VNL</td>\n",
       "      <td>WTDF22.5</td>\n",
       "      <td>WTDD22.5</td>\n",
       "      <td>UWTDT</td>\n",
       "      <td>WBF-ACCU</td>\n",
       "      <td>WBD-ACCU</td>\n",
       "      <td>UWBT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788696</th>\n",
       "      <td>4V4NC9EG9LN267768</td>\n",
       "      <td>D13</td>\n",
       "      <td>405</td>\n",
       "      <td>VNL</td>\n",
       "      <td>WTDF22.5</td>\n",
       "      <td>WTDD22.5</td>\n",
       "      <td>UWTDT</td>\n",
       "      <td>WBF-ACCU</td>\n",
       "      <td>WBD-ACCU</td>\n",
       "      <td>UWBT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788697</th>\n",
       "      <td>4V4NC9EG9LN267768</td>\n",
       "      <td>D13</td>\n",
       "      <td>405</td>\n",
       "      <td>VNL</td>\n",
       "      <td>WTDF22.5</td>\n",
       "      <td>WTDD22.5</td>\n",
       "      <td>UWTDT</td>\n",
       "      <td>WBF-ACCU</td>\n",
       "      <td>WBD-ACCU</td>\n",
       "      <td>UWBT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788698</th>\n",
       "      <td>4V4NC9EG9LN267768</td>\n",
       "      <td>D13</td>\n",
       "      <td>405</td>\n",
       "      <td>VNL</td>\n",
       "      <td>WTDF22.5</td>\n",
       "      <td>WTDD22.5</td>\n",
       "      <td>UWTDT</td>\n",
       "      <td>WBF-ACCU</td>\n",
       "      <td>WBD-ACCU</td>\n",
       "      <td>UWBT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1788699 rows × 723 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       VIN ENGINE_SIZE ENGINE_HP VEH_TYPE _KOLA_01X _KOLA_02X  \\\n",
       "0        4V4NC9EH6KN904736         D13       455      VNL  WTDF22.5  WTDD22.5   \n",
       "1        4V4NC9EH6KN904736         D13       455      VNL  WTDF22.5  WTDD22.5   \n",
       "2        4V4NC9EH6KN904736         D13       455      VNL  WTDF22.5  WTDD22.5   \n",
       "3        4V4NC9EH6KN904736         D13       455      VNL  WTDF22.5  WTDD22.5   \n",
       "4        4V4NC9EH6KN904736         D13       455      VNL  WTDF22.5  WTDD22.5   \n",
       "...                    ...         ...       ...      ...       ...       ...   \n",
       "1788694  4V4NC9EG9LN267768         D13       405      VNL  WTDF22.5  WTDD22.5   \n",
       "1788695  4V4NC9EG9LN267768         D13       405      VNL  WTDF22.5  WTDD22.5   \n",
       "1788696  4V4NC9EG9LN267768         D13       405      VNL  WTDF22.5  WTDD22.5   \n",
       "1788697  4V4NC9EG9LN267768         D13       405      VNL  WTDF22.5  WTDD22.5   \n",
       "1788698  4V4NC9EG9LN267768         D13       405      VNL  WTDF22.5  WTDD22.5   \n",
       "\n",
       "        _KOLA_03X _KOLA_04X _KOLA_05X _KOLA_06X  ... f_5_dtc2457_1th_15d  \\\n",
       "0           UWTDT  WBF-ALCO  WBD-ALCO      UWBT  ...                 0.0   \n",
       "1           UWTDT  WBF-ALCO  WBD-ALCO      UWBT  ...                 0.0   \n",
       "2           UWTDT  WBF-ALCO  WBD-ALCO      UWBT  ...                 0.0   \n",
       "3           UWTDT  WBF-ALCO  WBD-ALCO      UWBT  ...                 0.0   \n",
       "4           UWTDT  WBF-ALCO  WBD-ALCO      UWBT  ...                 0.0   \n",
       "...           ...       ...       ...       ...  ...                 ...   \n",
       "1788694     UWTDT  WBF-ACCU  WBD-ACCU      UWBT  ...                 0.0   \n",
       "1788695     UWTDT  WBF-ACCU  WBD-ACCU      UWBT  ...                 0.0   \n",
       "1788696     UWTDT  WBF-ACCU  WBD-ACCU      UWBT  ...                 0.0   \n",
       "1788697     UWTDT  WBF-ACCU  WBD-ACCU      UWBT  ...                 0.0   \n",
       "1788698     UWTDT  WBF-ACCU  WBD-ACCU      UWBT  ...                 0.0   \n",
       "\n",
       "        f_5_dtc2457_2nd_15d f_6_dtc2457_1th_15d f_6_dtc2457_2nd_15d  \\\n",
       "0                       0.0                 0.0                 0.0   \n",
       "1                       0.0                 0.0                 0.0   \n",
       "2                       0.0                 0.0                 0.0   \n",
       "3                       0.0                 0.0                 0.0   \n",
       "4                       0.0                 0.0                 0.0   \n",
       "...                     ...                 ...                 ...   \n",
       "1788694                 0.0                 0.0                 0.0   \n",
       "1788695                 0.0                 0.0                 0.0   \n",
       "1788696                 0.0                 0.0                 0.0   \n",
       "1788697                 0.0                 0.0                 0.0   \n",
       "1788698                 0.0                 0.0                 0.0   \n",
       "\n",
       "        f_7_dtc2457_1th_15d f_7_dtc2457_2nd_15d f_8_dtc2457_1th_15d  \\\n",
       "0                         0                   0                   0   \n",
       "1                         0                   0                   0   \n",
       "2                         0                   0                   0   \n",
       "3                         0                   0                   0   \n",
       "4                         0                   0                   0   \n",
       "...                     ...                 ...                 ...   \n",
       "1788694                   0                   0                   0   \n",
       "1788695                   0                   0                   0   \n",
       "1788696                   0                   0                   0   \n",
       "1788697                   0                   0                   0   \n",
       "1788698                   0                   0                   0   \n",
       "\n",
       "        f_8_dtc2457_2nd_15d if_parts_replaced_in_1th_15d  \\\n",
       "0                         0                            0   \n",
       "1                         0                            0   \n",
       "2                         0                            0   \n",
       "3                         0                            0   \n",
       "4                         0                            0   \n",
       "...                     ...                          ...   \n",
       "1788694                   0                            0   \n",
       "1788695                   0                            0   \n",
       "1788696                   0                            0   \n",
       "1788697                   0                            0   \n",
       "1788698                   0                            0   \n",
       "\n",
       "        if_parts_replaced_in_2nd_15d  \n",
       "0                                  0  \n",
       "1                                  0  \n",
       "2                                  0  \n",
       "3                                  0  \n",
       "4                                  0  \n",
       "...                              ...  \n",
       "1788694                            0  \n",
       "1788695                            0  \n",
       "1788696                            0  \n",
       "1788697                            0  \n",
       "1788698                            0  \n",
       "\n",
       "[1788699 rows x 723 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop through the arguments and print them\n",
    "if len(sys.argv) > 1:\n",
    "    thisVIN = sys.argv[1]\n",
    "    \n",
    "    comma_delimited_string_for_all_columns_names = sys.argv[2]\n",
    "    all_columns_names = comma_delimited_string_for_all_columns_names.split(',')\n",
    "        \n",
    "    the_calculator_jobID_for_thisVIN = sys.argv[3]\n",
    "    \n",
    "    print(f\"the_calculator_jobID_for_thisVIN: {the_calculator_jobID_for_thisVIN} \\n\")\n",
    "    file = open(f\"/storage/home/yqf5148/work/volvoPennState/Jobs/outputs2/outputForJob_{the_calculator_jobID_for_thisVIN}.txt\", \"a\")\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225ae4dd-ffda-4d3e-9b1f-746bc0d2d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "input_file_path = '/storage/home/yqf5148/work/volvoPennState/data/dataset/resultedData.csv'\n",
    "cleaned_file_path = '/storage/home/yqf5148/work/volvoPennState/data/dataset/cleaned_resultedData.csv'\n",
    "\n",
    "# Load and clean the CSV\n",
    "cleaned_resultedData = pd.read_csv(cleaned_file_path, header=None, names=all_columns_names, index_col=False, dtype='unicode')\n",
    "print(f\"cleaned_resultedData is read.\")\n",
    "file = open(f\"/storage/home/yqf5148/work/volvoPennState/Jobs/outputs2/outputForJob_{the_calculator_jobID_for_thisVIN}.txt\", \"a\")\n",
    "file.writelines([f\"cleaned_resultedData is read.\"])\n",
    "file.writelines(cleaned_resultedData)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8450066-b4ae-424e-8b76-f53edca973e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process each row...\n",
      "Processing row 0, VIN: D13, calendar_day: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 1, VIN: D13, calendar_day: 4\n",
      "Processing row 2, VIN: D13, calendar_day: 0\n",
      "Processing row 3, VIN: D13, calendar_day: 2\n",
      "Processing row 4, VIN: D13, calendar_day: 8\n",
      "Processing row 5, VIN: D13, calendar_day: 0\n",
      "Processing row 6, VIN: D13, calendar_day: 8\n",
      "Processing row 7, VIN: D13, calendar_day: 6\n",
      "Processing row 8, VIN: D13, calendar_day: 0\n",
      "Processing row 9, VIN: D13, calendar_day: 4\n",
      "Processing row 10, VIN: D13, calendar_day: 2\n",
      "Processing row 11, VIN: D13, calendar_day: 4\n",
      "Processing row 12, VIN: D13, calendar_day: 6\n",
      "Processing row 13, VIN: D13, calendar_day: 2\n",
      "Processing row 14, VIN: D13, calendar_day: 2\n",
      "Processing row 15, VIN: D13, calendar_day: 6\n",
      "Processing row 16, VIN: D13, calendar_day: 4\n",
      "Processing row 17, VIN: D13, calendar_day: 4\n",
      "Processing row 18, VIN: D13, calendar_day: 8\n",
      "Processing row 19, VIN: D13, calendar_day: 0\n",
      "Processing row 20, VIN: D13, calendar_day: 0\n",
      "Processing row 21, VIN: D13, calendar_day: 6\n",
      "Processing row 22, VIN: D13, calendar_day: 2\n",
      "Processing row 23, VIN: D13, calendar_day: 4\n",
      "Processing row 24, VIN: D13, calendar_day: 8\n",
      "Processing row 25, VIN: D13, calendar_day: 8\n",
      "Processing row 26, VIN: D13, calendar_day: 6\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Base date for calculating the 15-day intervals\n",
    "base_date = datetime.strptime('12/31/2021', '%m/%d/%Y')\n",
    "min_date = datetime.strptime('12/31/2014', '%m/%d/%Y')  # Restrict processing to dates after 01/01/2016\n",
    "max_calendar_day = (base_date - min_date).days\n",
    "\n",
    "# Initialize variables for batch processing\n",
    "batch_size = 50\n",
    "rows_to_write = []\n",
    "\n",
    "# Check if cleaned file already exists, to determine whether to write headers\n",
    "write_header = not os.path.exists(cleaned_file_path)\n",
    "\n",
    "# Filter the DataFrame to only process rows for this specific VIN\n",
    "df = cleaned_resultedData[cleaned_resultedData['VIN'] == thisVIN]\n",
    "\n",
    "# Track if any modification was made for this VIN\n",
    "modification_made = 0\n",
    "\n",
    "# Process each row\n",
    "print(f\"Starting to process data for VIN={thisVIN}...\")\n",
    "file = open(f\"/storage/home/yqf5148/work/volvoPennState/Jobs/outputs2/outputForJob_{the_calculator_jobID_for_thisVIN}.txt\", \"a\")\n",
    "file.writelines(f\"Starting to process data for VIN={thisVIN}...\\n\")\n",
    "file.close()\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    VIN = row.iloc[1]  # Access the second column in the row\n",
    "    \n",
    "    # Convert calendar_day to integer, skipping non-numeric rows\n",
    "    try:\n",
    "        calendar_day = int(pd.to_numeric(row['calendar_day'], errors='coerce'))\n",
    "    except ValueError:\n",
    "        print(f\"Skipping row {idx} due to invalid calendar_day value: {row['calendar_day']}\")\n",
    "        file = open(f\"/storage/home/yqf5148/work/volvoPennState/Jobs/outputs2/outputForJob_{the_calculator_jobID_for_thisVIN}.txt\", \"a\")\n",
    "        file.writelines(f\"Skipping row {idx} due to invalid calendar_day value: {row['calendar_day']}\\n\")\n",
    "        file.close()\n",
    "        continue\n",
    "\n",
    "    # Skip rows with calendar_day beyond the allowed range\n",
    "    if calendar_day > max_calendar_day:\n",
    "        print(f\"Skipping row {idx} because calendar_day exceeds 7 years: {calendar_day}\")\n",
    "        file = open(f\"/storage/home/yqf5148/work/volvoPennState/Jobs/outputs2/outputForJob_{the_calculator_jobID_for_thisVIN}.txt\", \"a\")\n",
    "        file.writelines(f\"Skipping row {idx} because calendar_day exceeds 7 years: {calendar_day}\\n\")\n",
    "        file.close()\n",
    "        continue\n",
    "\n",
    "    specific_date = base_date - timedelta(days=calendar_day)\n",
    "    print(f\"Processing row {idx}, VIN: {VIN}, calendar_day: {calendar_day}\")\n",
    "    file = open(f\"/storage/home/yqf5148/work/volvoPennState/Jobs/outputs2/outputForJob_{the_calculator_jobID_for_thisVIN}.txt\", \"a\")\n",
    "    file.writelines(f\"Processing row {idx}, VIN: {VIN}, calendar_day: {calendar_day}\\n\")\n",
    "    file.close()\n",
    "\n",
    "    # Initialize the replacement columns to zero\n",
    "    row_updated = False\n",
    "    if row[\"if_parts_replaced_in_1th_15d\"] != 1:\n",
    "        df.at[idx, \"if_parts_replaced_in_1th_15d\"] = 0\n",
    "    if row[\"if_parts_replaced_in_2nd_15d\"] != 1:\n",
    "        df.at[idx, \"if_parts_replaced_in_2nd_15d\"] = 0\n",
    "\n",
    "    # First 15-day interval (0 to 15 days back from specific_date)\n",
    "    for day_offset in range(15):\n",
    "        end_date = specific_date - timedelta(days=day_offset)\n",
    "        start_date = end_date - timedelta(days=15)\n",
    "\n",
    "        if if_part_is_replaced_for_this_VIN_in_this_timespan(VIN, start_date, end_date) == 1:\n",
    "            df.at[idx, \"if_parts_replaced_in_1th_15d\"] = 1\n",
    "            row_updated = True\n",
    "            modification_made = 1  # Set modification_made to 1 if any modification occurs\n",
    "            print(f\"  - Part replacement detected in the first 15-day interval for row {idx}.\")\n",
    "            file = open(f\"/storage/home/yqf5148/work/volvoPennState/Jobs/outputs2/outputForJob_{the_calculator_jobID_for_thisVIN}.txt\", \"a\")\n",
    "            file.writelines(f\"  - Part replacement detected in the first 15-day interval for row {idx}.\\n\")\n",
    "            file.close()\n",
    "            break\n",
    "\n",
    "    # Second 15-day interval (15 to 30 days back from specific_date)\n",
    "    for day_offset in range(15, 30):\n",
    "        end_date = specific_date - timedelta(days=day_offset)\n",
    "        start_date = end_date - timedelta(days=15)\n",
    "\n",
    "        if if_part_is_replaced_for_this_VIN_in_this_timespan(VIN, start_date, end_date) == 1:\n",
    "            df.at[idx, \"if_parts_replaced_in_2nd_15d\"] = 1\n",
    "            row_updated = True\n",
    "            modification_made = 1  # Set modification_made to 1 if any modification occurs\n",
    "            print(f\"  - Part replacement detected in the second 15-day interval for row {idx}.\")\n",
    "            file = open(f\"/storage/home/yqf5148/work/volvoPennState/Jobs/outputs2/outputForJob_{the_calculator_jobID_for_thisVIN}.txt\", \"a\")\n",
    "            file.writelines(f\"  - Part replacement detected in the second 15-day interval for row {idx}.\\n\")\n",
    "            file.close()\n",
    "            break\n",
    "\n",
    "    # Add the modified row to the list if updated\n",
    "    if row_updated:\n",
    "        rows_to_write.append((idx, row))  # Append as a tuple of (index, row)\n",
    "        print(f\"  - Row {idx} marked for writing due to updates.\")\n",
    "        file = open(f\"/storage/home/yqf5148/work/volvoPennState/Jobs/outputs2/outputForJob_{the_calculator_jobID_for_thisVIN}.txt\", \"a\")\n",
    "        file.writelines(f\"  - Row {idx} marked for writing due to updates.\\n\")\n",
    "        file.close()\n",
    "\n",
    "    # Write every 50 rows and reset buffer\n",
    "    if (idx + 1) % batch_size == 0 or idx == len(df) - 1:\n",
    "        if rows_to_write:\n",
    "            print(f\"Writing {len(rows_to_write)} rows to the output file at row {idx}.\")\n",
    "            file = open(f\"/storage/home/yqf5148/work/volvoPennState/Jobs/outputs2/outputForJob_{the_calculator_jobID_for_thisVIN}.txt\", \"a\")\n",
    "            file.writelines(f\"Writing {len(rows_to_write)} rows to the output file at row {idx}.\\n\")\n",
    "            file.close()\n",
    "\n",
    "            rows_to_write_df = pd.DataFrame([row for idx, row in rows_to_write])\n",
    "            rows_to_write_df.index = [idx for idx, row in rows_to_write]  # Set indices based on the original indices\n",
    "\n",
    "            cleaned_resultedData.update(rows_to_write_df)\n",
    "            cleaned_resultedData.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "            write_header = False  # Only write the header for the first batch\n",
    "            rows_to_write = []  # Reset list for the next batch\n",
    "\n",
    "# If there are any remaining rows in rows_to_write, write them as well\n",
    "if rows_to_write:\n",
    "    print(f\"Writing remaining {len(rows_to_write)} rows to the output file.\")\n",
    "    rows_to_write_df = pd.DataFrame([row for idx, row in rows_to_write])\n",
    "    rows_to_write_df.index = [idx for idx, row in rows_to_write]\n",
    "\n",
    "    cleaned_resultedData.update(rows_to_write_df)\n",
    "    cleaned_resultedData.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Mark this VIN as 'checked' in a separate file along with the modification status\n",
    "VIN_feature_columns = pd.DataFrame({'VIN': [thisVIN], 'modification_made': [modification_made]})\n",
    "VIN_feature_columns.to_csv('/storage/home/yqf5148/work/volvoPennState/data/dataset/VINs_data_part_repl.csv', index=False, mode='a', header=False) \n",
    "print(f\"{thisVIN} is marked as 'checked' for the part replacement with modification status {modification_made}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f616e313-d717-4897-978e-b158f7e89525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "volvopennstate_new_kernel",
   "language": "python",
   "name": "volvopennstate_new_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
